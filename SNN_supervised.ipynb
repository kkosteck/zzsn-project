{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_assignments,\n",
    "    plot_input,\n",
    "    plot_performance,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    "    plot_weights,\n",
    ")\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", type=int, default=0)\n",
    "parser.add_argument(\"--n_neurons\", type=int, default=100)\n",
    "parser.add_argument(\"--n_train\", type=int, default=60000)\n",
    "parser.add_argument(\"--n_test\", type=int, default=10000)\n",
    "parser.add_argument(\"--n_clamp\", type=int, default=1)\n",
    "parser.add_argument(\"--exc\", type=float, default=22.5)\n",
    "parser.add_argument(\"--inh\", type=float, default=120)\n",
    "parser.add_argument(\"--theta_plus\", type=float, default=0.05)\n",
    "parser.add_argument(\"--time\", type=int, default=250)\n",
    "parser.add_argument(\"--dt\", type=int, default=1.0)\n",
    "parser.add_argument(\"--intensity\", type=float, default=32)\n",
    "parser.add_argument(\"--progress_interval\", type=int, default=10)\n",
    "parser.add_argument(\"--update_interval\", type=int, default=250)\n",
    "parser.add_argument(\"--train\", dest=\"train\", action=\"store_true\")\n",
    "parser.add_argument(\"--test\", dest=\"train\", action=\"store_false\")\n",
    "parser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\")\n",
    "parser.add_argument(\"--gpu\", dest=\"gpu\", action=\"store_true\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0)\n",
    "parser.set_defaults(plot=True, gpu=True, train=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "seed = args.seed\n",
    "n_neurons = args.n_neurons\n",
    "n_train = args.n_train\n",
    "n_test = args.n_test\n",
    "n_clamp = args.n_clamp\n",
    "exc = args.exc\n",
    "inh = args.inh\n",
    "theta_plus = args.theta_plus\n",
    "time = args.time\n",
    "dt = args.dt\n",
    "intensity = args.intensity\n",
    "progress_interval = args.progress_interval\n",
    "update_interval = args.update_interval\n",
    "train = args.train\n",
    "plot = args.plot\n",
    "gpu = args.gpu\n",
    "device_id = args.device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "per_class = int(n_neurons / n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Diehl & Cook 2015 network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    nu=[1e-10, 1e-3],  # 0.711\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "\n",
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=time, device=device)\n",
    "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=time, device=device)\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create a dataloader to iterate and batch data\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(update_interval, time, n_neurons, device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "assignments = -torch.ones_like(torch.Tensor(n_neurons), device=device)\n",
    "proportions = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Labels to determine neuron assignments and spike proportions and estimate accuracy\n",
    "labels = torch.empty(update_interval, device=device)\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network.\n",
    "print(\"Begin training.\\n\")\n",
    "\n",
    "inpt_axes = None\n",
    "inpt_ims = None\n",
    "spike_axes = None\n",
    "spike_ims = None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes = None\n",
    "voltage_ims = None\n",
    "\n",
    "pbar = tqdm(total=n_train)\n",
    "for (i, datum) in enumerate(dataloader):\n",
    "    if i > n_train:\n",
    "        break\n",
    "\n",
    "    image = datum[\"encoded_image\"]\n",
    "    label = datum[\"label\"]\n",
    "\n",
    "    if i % update_interval == 0 and i > 0:\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(spike_record, assignments, n_classes)\n",
    "        proportion_pred = proportion_weighting(\n",
    "            spike_record, assignments, proportions, n_classes\n",
    "        )\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(\n",
    "            100 * torch.sum(labels.long() == all_activity_pred).item() / update_interval\n",
    "        )\n",
    "        accuracy[\"proportion\"].append(\n",
    "            100 * torch.sum(labels.long() == proportion_pred).item() / update_interval\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "            % (accuracy[\"all\"][-1], np.mean(accuracy[\"all\"]), np.max(accuracy[\"all\"]))\n",
    "        )\n",
    "        print(\n",
    "            \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\\n\"\n",
    "            % (\n",
    "                accuracy[\"proportion\"][-1],\n",
    "                np.mean(accuracy[\"proportion\"]),\n",
    "                np.max(accuracy[\"proportion\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(\n",
    "            spike_record, labels, n_classes, rates\n",
    "        )\n",
    "\n",
    "    # Add the current label to the list of labels for this update_interval\n",
    "    labels[i % update_interval] = label[0]\n",
    "\n",
    "    # Run the network on the input.\n",
    "    choice = np.random.choice(int(n_neurons / n_classes), size=n_clamp, replace=False)\n",
    "    clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n",
    "    if gpu:\n",
    "        inputs = {\"X\": image.cuda().view(time, 1, 1, 28, 28)}\n",
    "    else:\n",
    "        inputs = {\"X\": image.view(time, 1, 1, 28, 28)}\n",
    "    network.run(inputs=inputs, time=time, clamp=clamp)\n",
    "\n",
    "    # Get voltage recording.\n",
    "    exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "    inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[i % update_interval] = spikes[\"Ae\"].get(\"s\").view(time, n_neurons)\n",
    "\n",
    "    # Optionally plot various simulation information.\n",
    "    if plot:\n",
    "        inpt = inputs[\"X\"].view(time, 784).sum(0).view(28, 28)\n",
    "        input_exc_weights = network.connections[(\"X\", \"Ae\")].w\n",
    "        square_weights = get_square_weights(\n",
    "            input_exc_weights.view(784, n_neurons), n_sqrt, 28\n",
    "        )\n",
    "        square_assignments = get_square_assignments(assignments, n_sqrt)\n",
    "        voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "\n",
    "        inpt_axes, inpt_ims = plot_input(\n",
    "            image.sum(1).view(28, 28), inpt, label=label, axes=inpt_axes, ims=inpt_ims\n",
    "        )\n",
    "        spike_ims, spike_axes = plot_spikes(\n",
    "            {layer: spikes[layer].get(\"s\").view(time, 1, -1) for layer in spikes},\n",
    "            ims=spike_ims,\n",
    "            axes=spike_axes,\n",
    "        )\n",
    "        weights_im = plot_weights(square_weights, im=weights_im)\n",
    "        assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
    "        perf_ax = plot_performance(accuracy, x_scale=update_interval, ax=perf_ax)\n",
    "        voltage_ims, voltage_axes = plot_voltages(\n",
    "            voltages, ims=voltage_ims, axes=voltage_axes\n",
    "        )\n",
    "\n",
    "        plt.pause(1e-8)\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Train progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(\"Progress: %d / %d \\n\" % (n_train, n_train))\n",
    "print(\"Training complete.\\n\")\n",
    "\n",
    "print(\"Testing....\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(1, int(time / dt), n_neurons, device=device)\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "\n",
    "pbar = tqdm(total=n_test)\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step > n_test:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "    if gpu:\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(\n",
    "        spikes=spike_record, assignments=assignments, n_labels=n_classes\n",
    "    )\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "\n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(\n",
    "        torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "    )\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "    pbar.set_description_str(\n",
    "        f\"Accuracy: {(max(accuracy['all'] ,accuracy['proportion'] ) / (step+1)):.3}\"\n",
    "    )\n",
    "    pbar.update()\n",
    "\n",
    "print(\"\\nAll activity accuracy: %.2f\" % (accuracy[\"all\"] / n_test))\n",
    "print(\"Proportion weighting accuracy: %.2f \\n\" % (accuracy[\"proportion\"] / n_test))\n",
    "\n",
    "\n",
    "print(\"Testing complete.\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07ff98b09dfc4d9731a3c448dbce9600fd87f0e687e8651988bbe1fa4cad4e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('zzsn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
