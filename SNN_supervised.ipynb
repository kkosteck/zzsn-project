{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "n_clamp = 1\n",
    "exc = 22.5\n",
    "inh = 120\n",
    "theta_plus = 0.05\n",
    "time = 250\n",
    "dt = 1.0\n",
    "intensity = 32\n",
    "progress_interval = 10\n",
    "update_interval = 250\n",
    "train = True\n",
    "plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_classes = 10\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "per_class = int(n_neurons / n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Diehl & Cook 2015 network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    nu=[1e-10, 1e-3],  # 0.711\n",
    "    norm=78.4,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "# Directs network to GPU\n",
    "network.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader to iterate and batch data\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(update_interval, time, n_neurons, device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "assignments = -torch.ones_like(torch.Tensor(n_neurons), device=device)\n",
    "proportions = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Labels to determine neuron assignments and spike proportions and estimate accuracy\n",
    "labels = torch.empty(update_interval, device=device)\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network.\n",
    "print(\"Begin training.\\n\")\n",
    "\n",
    "pbar = tqdm(total=n_train)\n",
    "for (i, datum) in enumerate(dataloader):\n",
    "    if i > n_train:\n",
    "        break\n",
    "\n",
    "    image = datum[\"encoded_image\"]\n",
    "    label = datum[\"label\"]\n",
    "\n",
    "    if i % update_interval == 0 and i > 0:\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(spike_record, assignments, n_classes)\n",
    "        proportion_pred = proportion_weighting(spike_record, assignments, proportions, n_classes)\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(100 * torch.sum(labels.long() == all_activity_pred).item() / update_interval)\n",
    "        accuracy[\"proportion\"].append(100 * torch.sum(labels.long() == proportion_pred).item() / update_interval)\n",
    "\n",
    "        print(f\"\\nAll activity accuracy: {accuracy['all'][-1]:.2f} (last), {np.mean(accuracy['all']):.2f} (average), {np.max(accuracy['all']):.2f} (best)\")\n",
    "        print(f\"Proportion weighting accuracy: {accuracy['proportion'][-1]:.2f} (last), {np.mean(accuracy['proportion']):.2f} (average), {np.max(accuracy['proportion']):.2f} (best)\\n\")\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(spike_record, labels, n_classes, rates)\n",
    "\n",
    "    # Add the current label to the list of labels for this update_interval\n",
    "    labels[i % update_interval] = label[0]\n",
    "\n",
    "    # Run the network on the input.\n",
    "    choice = np.random.choice(int(n_neurons / n_classes), size=n_clamp, replace=False)\n",
    "    clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n",
    "    inputs = {\"X\": image.cuda().view(time, 1, 1, 28, 28)}\n",
    "    network.run(inputs=inputs, time=time, clamp=clamp)\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[i % update_interval] = spikes[\"Ae\"].get(\"s\").view(time, n_neurons)\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Train progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"Progress: {n_train} / {n_train} \\n\")\n",
    "print(\"Training complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing....\\n\")\n",
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=time, dt=dt),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(1, int(time / dt), n_neurons, device=device)\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "\n",
    "pbar = tqdm(total=n_test)\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step > n_test:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(time / dt), 1, 1, 28, 28)}\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    network.run(inputs=inputs, time=time, input_time_dim=1)\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(spikes=spike_record, assignments=assignments, n_labels=n_classes)\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "\n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(\n",
    "        torch.sum(label_tensor.long() == proportion_pred).item()\n",
    "    )\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "    pbar.set_description_str(f\"Accuracy: {(max(accuracy['all'] ,accuracy['proportion'] ) / (step+1)):.3}\")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"\\nAll activity accuracy: {(accuracy['all'] / n_test):.2f}\")\n",
    "print(f\"Proportion weighting accuracy: {(accuracy['proportion'] / n_test):.2f} \\n\")\n",
    "\n",
    "print(\"Testing complete.\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07ff98b09dfc4d9731a3c448dbce9600fd87f0e687e8651988bbe1fa4cad4e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('zzsn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
