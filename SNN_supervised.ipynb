{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.evaluation import all_activity, assign_labels, proportion_weighting\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config.json\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up Gpu use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "\n",
    "n_classes = 10\n",
    "n_sqrt = int(np.ceil(np.sqrt(config[\"n_neurons\"])))\n",
    "start_intensity = config[\"intensity\"]\n",
    "per_class = int(config[\"n_neurons\"] / n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiehlAndCook2015(\n",
       "  (X): Input()\n",
       "  (Ae): DiehlAndCookNodes()\n",
       "  (Ai): LIFNodes()\n",
       "  (X_to_Ae): Connection(\n",
       "    (source): Input()\n",
       "    (target): DiehlAndCookNodes()\n",
       "  )\n",
       "  (Ae_to_Ai): Connection(\n",
       "    (source): DiehlAndCookNodes()\n",
       "    (target): LIFNodes()\n",
       "  )\n",
       "  (Ai_to_Ae): Connection(\n",
       "    (source): LIFNodes()\n",
       "    (target): DiehlAndCookNodes()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Diehl & Cook 2015 network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=784,\n",
    "    n_neurons=config[\"n_neurons\"],\n",
    "    exc=config[\"exc\"],\n",
    "    inh=config[\"inh\"],\n",
    "    dt=config[\"dt\"],\n",
    "    nu=[1e-10, 1e-3],  # 0.711\n",
    "    norm=78.4,\n",
    "    theta_plus=config[\"theta_plus\"],\n",
    "    inpt_shape=(1, 28, 28),\n",
    ")\n",
    "# Directs network to GPU\n",
    "network.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "#exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=config[\"time\"], device=device)\n",
    "#inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=config[\"time\"], device=device)\n",
    "#network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "#network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n",
    "def config_monitor(net, time, device):\n",
    "    evm = Monitor(network.layers[\"Ae\"], [\"v\"], time=time, device=device)\n",
    "    ivm = Monitor(network.layers[\"Ai\"], [\"v\"], time=time, device=device)\n",
    "    net.add_monitor(evm, name=\"exc_voltage\")\n",
    "    net.add_monitor(ivm, name=\"inh_voltage\")\n",
    "    spikes_dict = {}\n",
    "    for layer in set(net.layers):\n",
    "        spikes_dict[layer] = Monitor(net.layers[layer], state_vars=[\"s\"], time=config[\"time\"])\n",
    "        net.add_monitor(spikes_dict[layer], name=f\"{layer}_spikes\")\n",
    "    return net, evm, ivm, spikes_dict\n",
    "network, exc_voltage_monitor, inh_voltage_monitor, spikes = config_monitor(network, config[\"time\"], device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data.\n",
    "dataset = MNIST(\n",
    "    PoissonEncoder(time=config[\"time\"], dt=config[\"dt\"]),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * config[\"intensity\"])]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader to iterate and batch data\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(config[\"update_interval\"], config[\"time\"], config[\"n_neurons\"], device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "assignments = -torch.ones_like(torch.Tensor(config[\"n_neurons\"]), device=device)\n",
    "proportions = torch.zeros_like(torch.Tensor(config[\"n_neurons\"], n_classes), device=device)\n",
    "rates = torch.zeros_like(torch.Tensor(config[\"n_neurons\"], n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Labels to determine neuron assignments and spike proportions and estimate accuracy\n",
    "labels = torch.empty(config[\"update_interval\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spikes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\01143577\\Desktop\\codes\\zzsn\\SNN_supervised.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/01143577/Desktop/codes/zzsn/SNN_supervised.ipynb#ch0000007?line=37'>38</a>\u001b[0m inh_voltages \u001b[39m=\u001b[39m inh_voltage_monitor\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/01143577/Desktop/codes/zzsn/SNN_supervised.ipynb#ch0000007?line=39'>40</a>\u001b[0m \u001b[39m# Add to spikes recording.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/01143577/Desktop/codes/zzsn/SNN_supervised.ipynb#ch0000007?line=40'>41</a>\u001b[0m spike_record[i \u001b[39m%\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mupdate_interval\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m spikes[\u001b[39m\"\u001b[39m\u001b[39mAe\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mview(config[\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m], config[\u001b[39m\"\u001b[39m\u001b[39mn_neurons\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/01143577/Desktop/codes/zzsn/SNN_supervised.ipynb#ch0000007?line=42'>43</a>\u001b[0m network\u001b[39m.\u001b[39mreset_state_variables()  \u001b[39m# Reset state variables.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/01143577/Desktop/codes/zzsn/SNN_supervised.ipynb#ch0000007?line=43'>44</a>\u001b[0m pbar\u001b[39m.\u001b[39mset_description_str(\u001b[39m\"\u001b[39m\u001b[39mTrain progress: \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spikes' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the network.\n",
    "print(\"Begin training.\\n\")\n",
    "\n",
    "pbar = tqdm(total=config[\"n_train\"])\n",
    "for (i, datum) in enumerate(dataloader):\n",
    "    if i > config[\"n_train\"]:\n",
    "        break\n",
    "\n",
    "    image = datum[\"encoded_image\"]\n",
    "    label = datum[\"label\"]\n",
    "\n",
    "    if i % config[\"update_interval\"] == 0 and i > 0:\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(spike_record, assignments, n_classes)\n",
    "        proportion_pred = proportion_weighting(spike_record, assignments, proportions, n_classes)\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(100 * torch.sum(labels.long() == all_activity_pred).item() / config[\"update_interval\"])\n",
    "        accuracy[\"proportion\"].append(100 * torch.sum(labels.long() == proportion_pred).item() / config[\"update_interval\"])\n",
    "\n",
    "        print(f\"\\nAll activity accuracy: {accuracy['all'][-1]:.2f} (last), {np.mean(accuracy['all']):.2f} (average), {np.max(accuracy['all']):.2f} (best)\")\n",
    "        print(f\"Proportion weighting accuracy: {accuracy['proportion'][-1]:.2f} (last), {np.mean(accuracy['proportion']):.2f} (average), {np.max(accuracy['proportion']):.2f} (best)\\n\")\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(spike_record, labels, n_classes, rates)\n",
    "\n",
    "    # Add the current label to the list of labels for this update_interval\n",
    "    labels[i % config[\"update_interval\"]] = label[0]\n",
    "\n",
    "    # Run the network on the input.\n",
    "    choice = np.random.choice(int(config[\"n_neurons\"] / n_classes), size=config[\"n_clamp\"], replace=False)\n",
    "    clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n",
    "    inputs = {\"X\": image.cuda().view(config[\"time\"], 1, 1, 28, 28)}\n",
    "    network.run(inputs=inputs, time=config[\"time\"], clamp=clamp)\n",
    "\n",
    "    # Get voltage recording.\n",
    "    exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "    inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[i % config[\"update_interval\"]] = spikes[\"Ae\"].get(\"s\").view(config[\"time\"], config[\"n_neurons\"])\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Train progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"Progress: {config['n_train']} / {config['n_train']} \\n\")\n",
    "print(\"Training complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing....\\n\")\n",
    "# Load MNIST data.\n",
    "test_dataset = MNIST(\n",
    "    PoissonEncoder(time=config[\"time\"], dt=config[\"dt\"]),\n",
    "    None,\n",
    "    root=os.path.join(\"..\", \"..\", \"data\", \"MNIST\"),\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * config[\"intensity\"])]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": 0, \"proportion\": 0}\n",
    "\n",
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(1, int(config[\"time\"] / config[\"dt\"]), config[\"n_neurons\"], device=device)\n",
    "\n",
    "# Train the network.\n",
    "print(\"\\nBegin testing\\n\")\n",
    "network.train(mode=False)\n",
    "\n",
    "pbar = tqdm(total=config[\"n_test\"])\n",
    "for step, batch in enumerate(test_dataset):\n",
    "    if step > config[\"n_test\"]:\n",
    "        break\n",
    "    # Get next input sample.\n",
    "    inputs = {\"X\": batch[\"encoded_image\"].view(int(config[\"time\"] / config[\"dt\"]), 1, 1, 28, 28)}\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # Run the network on the input.\n",
    "    network.run(inputs=inputs, time=config[\"time\"], input_time_dim=1)\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[0] = spikes[\"Ae\"].get(\"s\").squeeze()\n",
    "\n",
    "    # Convert the array of labels into a tensor\n",
    "    label_tensor = torch.tensor(batch[\"label\"], device=device)\n",
    "\n",
    "    # Get network predictions.\n",
    "    all_activity_pred = all_activity(spikes=spike_record, assignments=assignments, n_labels=n_classes)\n",
    "    proportion_pred = proportion_weighting(\n",
    "        spikes=spike_record,\n",
    "        assignments=assignments,\n",
    "        proportions=proportions,\n",
    "        n_labels=n_classes,\n",
    "    )\n",
    "\n",
    "    # Compute network accuracy according to available classification strategies.\n",
    "    accuracy[\"all\"] += float(torch.sum(label_tensor.long() == all_activity_pred).item())\n",
    "    accuracy[\"proportion\"] += float(torch.sum(label_tensor.long() == proportion_pred).item())\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "\n",
    "    pbar.set_description_str(f\"Accuracy: {(max(accuracy['all'] ,accuracy['proportion'] ) / (step+1)):.3}\")\n",
    "    pbar.update()\n",
    "\n",
    "print(f\"\\nAll activity accuracy: {(accuracy['all'] / config['n_test']):.2f}\")\n",
    "print(f\"Proportion weighting accuracy: {(accuracy['proportion'] / config['n_test']):.2f} \\n\")\n",
    "\n",
    "print(\"Testing complete.\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07ff98b09dfc4d9731a3c448dbce9600fd87f0e687e8651988bbe1fa4cad4e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('zzsn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
